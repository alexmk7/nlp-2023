{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формальные языки\n",
    "\n",
    "**Формальный язык** — множество конечных слов над конечным алфавитом $\\Sigma$. \n",
    "Пусть есть некоторое конечно множество символов $\\Sigma$, тогда множество $L \\in \\Sigma^*$ есть формальный язык. \n",
    "\n",
    "Над формальными языками можно определить операции:\n",
    "\n",
    "* $L_1 \\cap L_2$\n",
    "* $L_1 \\cup L_2$\n",
    "* $L_1 \\setminus L_2$\n",
    "* $L_1 \\cdot L_2 $ - новый язык, в котором ко всем возможным словам из $L_1$ присоеденены справа слова из $L_2$\n",
    "* $L^*$ - замыкание клини, $\\{\\epsilon\\} \\cup L \\cup (L \\cdot L) \\cup (L \\cdot L \\cdot L) \\cup \\cdots$\n",
    "\n",
    "**Иерархия Хомского** — классификация формальных языков и формальных грамматик, согласно которой они делятся на 4 типа по их условной сложности"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Контекстно-свободная грамматикой**  называется четверка $G = (V, \\Sigma, R, S)$б где\n",
    "\n",
    "- $V$  - конечное множество нетерминальных символов\n",
    "- $\\Sigma$ - конечно множество терминальных символов (алфавит формального языка)\n",
    "- $R$  - конечное множество правил  вида $V \\rightarrow (V \\cup \\Sigma)^{*}$\n",
    "- $S \\in V$ - начальный нетерминал\n",
    "\n",
    "### Примеры КС-грамматик\n",
    "\n",
    "**Язык правильных скобочных записей**\n",
    "\n",
    "$S \\rightarrow (S)S$\n",
    "\n",
    "$S \\rightarrow \\epsilon$\n",
    "\n",
    "Нетерминалы: $\\{S\\}$, терминалы: $\\{(, )\\}$, начальный нетерминал: $S$\n",
    "\n",
    "**Математические выражения**\n",
    "\n",
    "$S \\rightarrow S + P\\,|\\,S - P\\,|\\,P$\n",
    "\n",
    "$P \\rightarrow A\\,|\\,P \\cdot A\\,|\\,P / A$\n",
    "\n",
    "$A \\rightarrow  \\mathbb{num}|\\,(S)$\n",
    "\n",
    "Нетерминалы: $\\{S, P, A\\}$, терминалы: $\\{(, ), \\mathbb{num}\\}$, начальный нетерминал: $S$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбор КС-грамматик\n",
    "\n",
    "Задача алгоритма разбора: по заданной грамматике и строке определить, принадлежит ли строка языку, порождаемому этой грамматикой, и построить дерево разбора\n",
    "\n",
    "Существуют различные типы КС-грамматик:\n",
    "- $LL$ \n",
    "- $LALR$\n",
    "- $SLR$\n",
    "- $LR$\n",
    "\n",
    "Распознаватели строятся по алгоритмам оптимальным для соответствующего типа (применяются при разборе языков программирования). Разбор входной строки обычно идет слева направо, дерево вывода может строиться сверху вниз или снизу вверх.\n",
    "\n",
    "Любая КС-грамматика может быть преобразована к эквивалентной грамматике к нормальной форме Хомского. Грамматика имеет вид нормальной формы Хомского, если ее правила имеют вид:\n",
    "\n",
    "$\\: A \\rightarrow BC$ \n",
    "\n",
    "$\\: A \\rightarrow \\alpha$ \n",
    "\n",
    "$\\: S \\rightarrow \\epsilon$\n",
    "\n",
    "**Алгоритм Кока — Янгера — Касами (CYK)** - алгоритм синтаксического анализа статьи, реализует вывод снизу-вверх, используется динамическое программирование. Сложность - $\\mathcal{O}\\left( n^3 \\cdot \\left| R \\right| \\right)$, где $n$ - размер строки, $R$ - правила грамматики в нормально форме Хомского.\n",
    "\n",
    "Идея: пусть входная строк $w$. Строится таблица $d[A][i][j]$ с данными о возможности вывода  $w[i..j]$ из правила $A$.\n",
    "\n",
    "**Алгоритм Эрли** - динамический алгоритм, строит вывод сверху вниз. Не требует преобразования к нормальной форме Хомского."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Иерархия Хомского\n",
    "\n",
    " Классификация формальных грамматик (и, соответственно, порождаемых ими языков), согласно которой они делятся на 4 типа, в зависимости от их  сложности. Предложена лингвистом Ноамом Хомским. \n",
    "\n",
    " #### Тип 3 — регулярные\n",
    " Сюда входят регулярные языки.  Регулярный язык (помимо регулярных выражений, конечных автоматов) можно задать с помощью КС-грамматик, где продукции выглядят так: $A \\rightarrow a$ или $A \\rightarrow aB$\n",
    "\n",
    "#### Тип 2 — контекстно-свободные\n",
    "Контекстно свободные грамматики и порождаемые ими языки\n",
    "\n",
    "#### Тип 1 — контекстно-зависимые\n",
    "Контекстно зависимые грамматики и порождаемые ими языки. Правила выводы выглядят так $\\alpha A \\beta \\rightarrow \\alpha \\gamma \\beta$\n",
    "\n",
    "#### Тип 0 — неограниченные\n",
    "Нет никаких ограничений"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотека [LARK](https://github.com/lark-parser/)\n",
    "\n",
    "Библиотека синтаксического разбора для `Python`. Реализует алгоритм Эрли и $LALR(1)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lark import Lark, Tree\n",
    "\n",
    "\n",
    "calc_grammar = \"\"\"\n",
    "    ?start: sum\n",
    "\n",
    "    ?sum: product\n",
    "        | sum \"+\" product   -> add\n",
    "        | sum \"-\" product   -> sub\n",
    "\n",
    "    ?product: atom\n",
    "        | product \"*\" atom  -> mul\n",
    "        | product \"/\" atom  -> div\n",
    "\n",
    "    ?atom: NUMBER           -> number\n",
    "         | \"(\" sum \")\"\n",
    "\n",
    "    %import common.CNAME -> NAME\n",
    "    %import common.NUMBER\n",
    "    %import common.WS_INLINE\n",
    "\n",
    "    %ignore WS_INLINE\n",
    "\"\"\"\n",
    "\n",
    "calc_parser = Lark(calc_grammar, parser='lalr')\n",
    "tree = calc_parser.parse(\"(1 + 2) * 5\")\n",
    "\n",
    "def calc(tree: Tree) -> int:\n",
    "    match tree.data:\n",
    "        case \"mul\":\n",
    "            return calc(tree.children[0]) * calc(tree.children[1])\n",
    "        case \"sub\":\n",
    "            return calc(tree.children[0]) - calc(tree.children[1])\n",
    "        case \"add\":\n",
    "            return calc(tree.children[0]) + calc(tree.children[1])\n",
    "        case \"div\":\n",
    "            return calc(tree.children[0]) / calc(tree.children[1])\n",
    "        case \"number\":\n",
    "            return int(tree.children[0])\n",
    "\n",
    "calc(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pyparsing](https://github.com/pyparsing/pyparsing/)\n",
    "\n",
    "Ещё одна библиотека синтаксического разбора для `Python`. Грамматика описывается с помощью специального DSL (domain-specific language, предметно-ориентированный язык).\n",
    "\n",
    "Опишем грамматику, котора позволяет разобрать записи вида: \n",
    ">   <слово>: число, число, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResults(['hello', '1', '22', '3'], {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyparsing import Word, alphas, nums,  Literal, StringEnd, ZeroOrMore, Suppress, OneOrMore \n",
    "\n",
    "word = Word(alphas)\n",
    "num = Word(nums)\n",
    "sep = Suppress(OneOrMore(','))\n",
    "col = Suppress(':')\n",
    "\n",
    "s = word + col + num + ZeroOrMore(sep + num) + StringEnd()\n",
    "        \n",
    "s.parseString('hello: 1, 22, 3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более сложный пример, грамматика описывает правильные скобочные записи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResults(['(', '(', ')', ')', '(', ')', '(', ')'], {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyparsing import Literal, Forward, StringEnd, OneOrMore, Empty\n",
    "\n",
    "br_o = Literal('(')\n",
    "br_c = Literal(')')\n",
    "\n",
    "braces = Forward()\n",
    "braces << OneOrMore(br_o + (braces | Empty() ) + br_c)\n",
    "start = braces + StringEnd()\n",
    "        \n",
    "start.parseString('(())()()')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [YARGY](https://github.com/natasha/yargy)\n",
    "\n",
    "Библиотека для извлечения структурированных данных из текста на русском языке. Аналог [Tomita Parser](https://github.com/yandex/tomita-parser/).\n",
    "\n",
    "Для разбора текста используется алгоритм Эрли и Pymorphy2 для работы с морфологией."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую грамматику для поиска упоминаний улиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Таврической', 'улицы']\n",
      "['Первой', 'Рождественской', 'улицы']\n",
      "['Мариинский', 'проезд']\n"
     ]
    }
   ],
   "source": [
    "from yargy import Parser, rule, and_, or_\n",
    "from yargy.predicates import gram, is_capitalized, dictionary\n",
    "\n",
    "\n",
    "ST = rule(\n",
    "    and_(\n",
    "        gram('ADJF'),  \n",
    "        is_capitalized()\n",
    "    ),\n",
    "    gram('ADJF').optional().repeatable(),\n",
    "    dictionary({\n",
    "        \"улица\",\n",
    "        \"переулок\",\n",
    "        \"проезд\"\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "text = \"Я шел по городу от Таврической улицы и в итоге дошел до Первой Рождественской улицы. Мариинский проезд остался позади.\"  \n",
    "parser = Parser(ST)\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более сложные грамматики для определения адресов и других именованных сущностей есть в библиотеке [Natasha](https://github.com/natasha/natasha/blob/master/natasha/grammars/addr.py)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате работы парсера мы получаем дерево разбора. Иногда удобнее сразу интерпретировать узлы дерева в качестве объектов - фактов. Например, мы хотим извлечь данные о занимаемой должности и имени. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(position='директор', name=Name(first='антон', last='иванов'))\n"
     ]
    }
   ],
   "source": [
    "from yargy import Parser\n",
    "from yargy.predicates import gram\n",
    "from yargy.pipelines import morph_pipeline\n",
    "from yargy.interpretation import fact\n",
    "\n",
    "Person = fact(\n",
    "    \"Person\",\n",
    "    [\"position\", \"name\"]\n",
    ")\n",
    "Name = fact(\n",
    "    \"Name\",\n",
    "    [\"first\", \"last\"]\n",
    ")\n",
    "\n",
    "POSITION = morph_pipeline([\n",
    "    \"директор\",\n",
    "    \"руководитель\"\n",
    "])\n",
    "\n",
    "ORG = morph_pipeline([\n",
    "    \"фирма\",\n",
    "    \"предприятие\"\n",
    "])\n",
    "\n",
    "NAME = rule(\n",
    "    gram(\"Name\").interpretation(\n",
    "        Name.first.inflected()\n",
    "    ),\n",
    "    gram(\"Surn\").interpretation(\n",
    "        Name.last.inflected()\n",
    "    )\n",
    ").interpretation(\n",
    "    Name\n",
    ")\n",
    "\n",
    "PERSON = rule(\n",
    "    POSITION.interpretation(\n",
    "        Person.position.inflected()\n",
    "    ),\n",
    "    ORG,\n",
    "    NAME.interpretation(\n",
    "        Person.name\n",
    "    )\n",
    ").interpretation(\n",
    "    Person\n",
    ")\n",
    "\n",
    "\n",
    "parser = Parser(PERSON)\n",
    "text = \"Директора предприятия Антон Иванов поздравил коллектив с праздником.\"\n",
    "for match in parser.findall(text):\n",
    "    print(match.fact)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда в правилах нужно иметь согласование по роду, числу или падежу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Петру', 'Марков']\n",
      "['Петр', 'Марков']\n"
     ]
    }
   ],
   "source": [
    "from yargy.relations import gnc_relation\n",
    "\n",
    "NAME = rule(\n",
    "    gram(\"Name\"),\n",
    "    gram(\"Surn\")\n",
    ")\n",
    "\n",
    "parser = Parser(NAME)\n",
    "for match in parser.findall(\"Петру Марков, Петр Марков\"):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в этом случае можно использовать `gnc_relation()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Петр', 'Марков']\n"
     ]
    }
   ],
   "source": [
    "gnc = gnc_relation()\n",
    "\n",
    "NAME = rule(\n",
    "    gram(\"Name\").match(gnc),\n",
    "    gram(\"Surn\").match(gnc)\n",
    ")\n",
    "\n",
    "\n",
    "parser = Parser(NAME)\n",
    "for match in parser.findall(\"Петру Марков, Петр Марков\"):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
